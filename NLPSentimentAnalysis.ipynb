{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Sentiment Analysis from scratch\n",
    "\n",
    "## Bogdan Macovei, Grupa 344\n",
    "## Universitatea din Bucuresti, Facultatea de Matematica si Informatica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['El se duce sa vada unde este.', \n",
    "          'Se pare ca este unde se credea.', \n",
    "          'Cine se duce sa il caute?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El se duce sa vada unde este.',\n",
       " 'Se pare ca este unde se credea.',\n",
       " 'Cine se duce sa il caute?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in range(0, len(corpus)):\n",
    "    word = corpus[i].split(' ')\n",
    "    for j in range(0, len(word)):\n",
    "        words.append(word[j].replace(\"-\", '').replace(\",\", '').replace(\".\", '').replace(\"[\", '')\n",
    "             .replace(\"]\", '').replace(\"_\", '').replace(\"\\\\\", '').replace(\"\\'\", '')\n",
    "             .replace(\"0\", '').replace(\"1\", '').replace(\"2\", '').replace(\"3\", '').replace(\"4\", '')\n",
    "             .replace(\"5\", '').replace(\"6\", '').replace(\"7\", '').replace(\"8\", '').replace(\"9\", '')\n",
    "             .replace(\"(\", '').replace(\")\", '').replace(\"?\", '').lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(words)\n",
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(corpus), len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(corpus)):\n",
    "    for j in range(0, len(words)):\n",
    "        X[i][j] = corpus[i].lower().count(words[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 2.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = list(map(lambda x: list(map(lambda y: y / len(x), x)), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(corpus)\n",
    "idf = np.zeros((len(corpus), len(words)))\n",
    "for j in range(0, len(words)):\n",
    "    count = 0\n",
    "    for i in range(0, N):\n",
    "        if X[i][j] != 0:\n",
    "            count = count + 1\n",
    "        if count != 0:\n",
    "            for i in range(0, N):\n",
    "                if X[i][j] != 0:\n",
    "                    idf[i][j] = math.log(N / count)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.40546511, 0.        , 1.09861229, 0.40546511,\n",
       "        1.09861229, 0.        , 0.        , 0.        , 0.40546511,\n",
       "        0.        , 0.40546511, 0.        ],\n",
       "       [1.09861229, 0.40546511, 1.09861229, 0.        , 0.        ,\n",
       "        0.        , 0.40546511, 0.        , 0.        , 0.40546511,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.40546511,\n",
       "        0.        , 0.40546511, 1.09861229, 1.09861229, 0.        ,\n",
       "        1.09861229, 0.40546511, 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693],\n",
       " [0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.15384615384615385],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.0,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693,\n",
       "  0.07692307692307693]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.03118962, 0.        , 0.08450864, 0.03118962,\n",
       "        0.08450864, 0.        , 0.        , 0.        , 0.03118962,\n",
       "        0.        , 0.03118962, 0.        ],\n",
       "       [0.08450864, 0.03118962, 0.08450864, 0.        , 0.        ,\n",
       "        0.        , 0.03118962, 0.        , 0.        , 0.03118962,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.03118962,\n",
       "        0.        , 0.03118962, 0.08450864, 0.08450864, 0.        ,\n",
       "        0.08450864, 0.03118962, 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf * idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Movie Review - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preluarea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.tsv', 'r') as fin:\n",
    "    cr = csv.reader(fin, delimiter='\\t')\n",
    "    corpus = [line for line in cr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in range(0, len(corpus)):\n",
    "    df.append(corpus[i][2]\n",
    "      .replace(\"-\", '').replace(\",\", '').replace(\".\", '').replace(\"[\", '')\n",
    "      .replace(\"]\", '').replace(\"_\", '').replace(\"\\\\\", '').replace(\"\\'\", '')\n",
    "      .replace(\"0\", '').replace(\"1\", '').replace(\"2\", '').replace(\"3\", '').replace(\"4\", '')\n",
    "      .replace(\"5\", '').replace(\"6\", '').replace(\"7\", '').replace(\"8\", '').replace(\"9\", '')\n",
    "      .replace(\"(\", '').replace(\")\", '').lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicare Tfidf-vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(strip_accents='ascii', stop_words='english', token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "vector = vectorizer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 15896)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i in range(0, len(corpus)):\n",
    "    if (corpus[i][3] == '0' or corpus[i][3] == '1'):\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a antrena mai rapid, vom limita setul de date (e doar demonstrativ, pentru o analiza reala se elimina celula urmatoare):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:8000]\n",
    "y = y[0:8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split-uim datele in train si test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(0, X.shape[0]):\n",
    "    if i % 5 == 0:\n",
    "        X_test.append(X[i])\n",
    "        y_test.append(y[i])\n",
    "    else:\n",
    "        X_train.append(X[i])\n",
    "        y_train.append(y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definim o functie care sa ne ajute in evaluarea modelului:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(prediction, y_test):\n",
    "    tp = 0; tn = 0; fp = 0; fn = 0;\n",
    "    for i in range(0, len(prediction)):\n",
    "        if prediction[i] == 0 and y_test[i] == 0:\n",
    "            tn = tn + 1\n",
    "        elif prediction[i] == 1 and y_test[i] == 1:\n",
    "            tp = tp + 1\n",
    "        elif prediction[i] == 1 and y_test[i] == 0:\n",
    "            fp = fp + 1\n",
    "        else:\n",
    "            fn = fn + 1\n",
    "        \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definim functia sigmoid, necesara antrenarii modelului in implementarea Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antrenarea modelului"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelul Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X_train, y_train):\n",
    "    m = len(X_train); n = len(X_train[0])\n",
    "    \n",
    "    weights = np.zeros((n, 1))\n",
    "    weights = weights.reshape((n, 1))\n",
    "    bias = np.zeros((1, 1))\n",
    "    \n",
    "    max_iter = 1 # setam numarul de perioade de evolutie\n",
    "    \n",
    "    for iteration in range(0, max_iter):\n",
    "        print(iteration, '/', max_iter - 1)\n",
    "        errors = 0\n",
    "        for i in range(0, m):\n",
    "            xi = np.array(X_train[i])\n",
    "            xi = xi.reshape((n, 1))\n",
    "            predicted = np.sign(weights.T.dot(xi) + bias)\n",
    "            \n",
    "            if y_train[i] * predicted <= 0:\n",
    "                weights = weights + y_train[i] * xi\n",
    "                bias = bias + y_train[i]\n",
    "                errors = errors + 1\n",
    "                \n",
    "        if errors == 0:\n",
    "            break\n",
    "        \n",
    "        y_pred = np.sign(X_t.dot(weights) + bias)\n",
    "        precision, recall, accuracy = model_evaluation(y_pred, y_test)\n",
    "        print('Errors:', errors, 'Train accuracy:', (m - errors) / m, 'Test accuracy:', accuracy)\n",
    "        print('')\n",
    "        \n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru rapiditate, vom antrena pe o singura epoca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 0\n",
      "Errors: 4715 Train accuracy: 0.8035416666666667 Test accuracy: 0.7998333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_t = np.array(X_test)\n",
    "weights, bias = perceptron(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.sign(X_t.dot(weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, accuracy = model_evaluation(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7998333333333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7998333333333333"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelul utilizand Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescentFit(X_train, y_train):\n",
    "    m = len(X_train); alpha = 1e-1; coef = alpha/m\n",
    "    oldW = np.random.rand(len(X_train[0]) + 1)\n",
    "    oldW = oldW.reshape((len(X_train[0]) + 1, 1))\n",
    "\n",
    "    localX_train = list(X_train)\n",
    "    localX_train = np.array(list(map(lambda x: np.concatenate([[1], x]), localX_train))) # adaug o coloana de 1\n",
    "    \n",
    "    localy_train = np.array(y_train)\n",
    "    localy_train = localy_train.reshape((len(y_train), 1))\n",
    "    \n",
    "    while 1:\n",
    "        product = localX_train.dot(oldW)\n",
    "        applied_sigmoid = np.array(list(map(lambda x: sigmoid(x), product)))\n",
    "        applied_sigmoid = applied_sigmoid.reshape(localy_train.shape)\n",
    "        \n",
    "        newW = oldW - coef * localX_train.T.dot(applied_sigmoid - localy_train)\n",
    "        \n",
    "        if np.linalg.norm(newW) > np.linalg.norm(oldW):\n",
    "            print(np.linalg.norm(newW) - np.linalg.norm(oldW))\n",
    "            break\n",
    "        \n",
    "        oldW = newW\n",
    "    \n",
    "    return newW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = GradientDescentFit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = list(X_test)\n",
    "X_t = np.array(list(map(lambda x: np.concatenate([[1], x]), X_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_init = X_t.dot(weights)\n",
    "y_pred = list(map(lambda x: round(sigmoid(x)), pred_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.800625 Recall:  1.0 Accuracy:  0.800625\n"
     ]
    }
   ],
   "source": [
    "precision, recall, accuracy = model_evaluation(y_pred, y_test)\n",
    "print('Precision: ', precision, 'Recall: ', recall, 'Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
